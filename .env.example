# LLM Provider: "gemini" or "ollama"
LLM_PROVIDER=gemini

# Gemini Configuration (recommended)
GEMINI_API_KEY=AIzaSyCB-BApFGljSkU0oqU3nS3_3e06H2pOMFM
GEMINI_MODEL=gemini-2.0-flash

# Ollama Configuration (fallback/local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# RAG Configuration
SIMILARITY_THRESHOLD=0.5
CHUNK_SIZE=500
CHUNK_OVERLAP=50
TOP_K_RESULTS=3

# Conversation Settings
MAX_HISTORY_LENGTH=6

# Data Paths
DATA_DIR=data
CHROMA_PERSIST_DIR=db/savta_collection
CHROMA_COLLECTION_NAME=savta_memories
